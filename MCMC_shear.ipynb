{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680fa990",
   "metadata": {},
   "source": [
    "# Monte Carlo Markov Chains para Cosmic Shear\n",
    "\n",
    "Agora que vimos os conceitos básicos de MCMC e análise estatística, é a sua vez. A Gabriela gerou dados observacionais de lenteamento gravitacional fraco de galáxias, enquanto o Guilherme explicou como fornecer previsões teóricas. O objetivo é obter intervalos de confiança para dois parâmetros cosmológicos:\n",
    "- $\\Omega_m$: fração que matéria não-relativística (\"baryons\" + dark matter + neutrinos massivos) representam da energia total no Universo;\n",
    "- $\\sigma_8$: variância do campo de densidade de matéria $\\delta_m(\\mathbf{x}, z = 0)$ dentro de esferas de raio $R = 8h/\\mathrm{Mpc}$.\n",
    "\n",
    "Vou deixar vocês com um código base, copiado da Gabriela e do Guilherme.\n",
    "\n",
    "Me chamem se tiverem qualquer dúvida ou problema!\n",
    "\n",
    "Dicas:\n",
    "- O notebook `MCMC_supernovas.ipynb` já tem uma implementação de Metropolis-Hastings pronta. Você pode copiar e colar, mas tem que refatorar o código para esse problema:\n",
    "  - É necessário mudar os parâmetros que são sampleados\n",
    "  - Repensar priors e proposal (proposal Gaussiano funciona melhor, mas precisa de uma covariância)\n",
    "- Os $C_\\ell$ teóricos são dados em $\\ell$ inteiro, enquanto os dados são binados, e portanto tem $\\ell$ fracionário. Talvez você queira aplicar uma interpolação\n",
    "- Você pode explorar alguns valores de $\\Omega_m$ e $\\sigma_8$ na mão usando a célula acima: isso pode te dar uma informação valiosa sobre o ponto inicial da MCMC, uma vez que começar de um ponto com alta *likelihood* melhora a velocidade de convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from classy import Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7904f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz, nz = np.load(\"data/dndz_input_z3_lensing_field_lsstlike.npy\")\n",
    "np.savetxt(\"data/dndz_class.txt\", np.stack((zz, nz), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ff701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cl_kk(Omega_m, sigma_8, lmax=2200):\n",
    "    params = {\n",
    "        # Saídas necessárias (CMB + LSS)\n",
    "        'modes': 's',\n",
    "        'output': 'mPk, sCl',\n",
    "        'l_max_lss': lmax,\n",
    "\n",
    "        # Energia escura via fld\n",
    "        'Omega_Lambda': 0,\n",
    "        'w0_fld': '-1.',\n",
    "        'wa_fld': '0.0',\n",
    "\n",
    "        # Espectro primordial (n_s fixo; sigma8 varia no loop)\n",
    "        'n_s': 0.96,\n",
    "\n",
    "        # Verbosidade e gauge\n",
    "        'background_verbose': 0,\n",
    "        'perturbations_verbose': 0,\n",
    "        'gauge': 'Synchronous',\n",
    "\n",
    "        # P(k) linear\n",
    "        'z_pk': '1.0, 0.0',\n",
    "        'P_k_max_h/Mpc': 10,\n",
    "        'k_per_decade_for_pk': 30,\n",
    "        'non linear': 'halofit',\n",
    "\n",
    "        # Fundo\n",
    "        'h': 0.673,\n",
    "        'Omega_b': 0.05,\n",
    "\n",
    "        'dNdz_selection': 'data/dndz_class.txt',\n",
    "\n",
    "        'N_ncdm': 1,\n",
    "        'm_ncdm': 0.06,\n",
    "        'T_ncdm': 0.7137658555036082,\n",
    "        'N_ur': 2.046,\n",
    "    }\n",
    "    Omega_nu_fid = 0.06/93.15/params['h']**2\n",
    "    params.update({\n",
    "        'Omega_cdm': Omega_m - params['Omega_b']  - Omega_nu_fid,\n",
    "        'sigma8': sigma_8,\n",
    "        # \"A_s\": 2e-9\n",
    "    })\n",
    "    \n",
    "    cosmo = Class()\n",
    "    cosmo.set(params)\n",
    "    cosmo.compute()\n",
    "    \n",
    "    cl = cosmo.density_cl(lmax)\n",
    "    Cl_kk = 2.5*np.asarray(cl['ll']['lens[1]-lens[1]'])\n",
    "    ell = np.arange(len(Cl_kk))\n",
    "\n",
    "    return ell, np.asarray(Cl_kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_kk_input = np.load(\"data/cl_kk_input_class.npy\")\n",
    "cl_kk_input = np.load(\"data/old/cl_kkgal_input_old.npy\")\n",
    "ell_input = np.arange(len(cl_kk_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução:\n",
    "from random import uniform\n",
    "from time import time\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "ell_data, cl_kk_data, sigma_cl_kk = np.load(\"teste_ell_Cl_errobar_kk_gal.npy\")\n",
    "\n",
    "# Alguns pontos são zero, vamos retirá-los nos dados\n",
    "mask = cl_kk_data > 0\n",
    "ell_data = ell_data[mask]\n",
    "cl_kk_data = cl_kk_data[mask]\n",
    "sigma_cl_kk = sigma_cl_kk[mask]\n",
    "mask = ell_data > 200\n",
    "ell_data = ell_data[mask]\n",
    "cl_kk_data = cl_kk_data[mask]\n",
    "sigma_cl_kk = sigma_cl_kk[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de cosmologia vs teoria\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "ell_theory, cl_kk_theory = get_cl_kk(Omega_m=0.35, sigma_8=0.840, lmax=7500)\n",
    "fac_theory = (ell_theory**4 + 2*ell_theory**3 - ell_theory*2 - 2*ell_theory)/4\n",
    "axs[0].loglog(ell_theory, fac_theory*cl_kk_theory)\n",
    "axs[0].errorbar(ell_data, cl_kk_data, yerr=sigma_cl_kk, color=\"black\", markersize=10, ls=\"none\")\n",
    "axs[0].set_xlabel(r\"$\\ell$\")\n",
    "axs[0].set_ylabel(r\"$C_\\ell^{\\kappa\\kappa}$\")\n",
    "\n",
    "cl_theory_interpolator = interp1d(ell_theory, fac_theory*cl_kk_theory)\n",
    "cl_kk_theory = cl_theory_interpolator(ell_data)\n",
    "axs[1].errorbar(ell_data, (cl_kk_data-cl_kk_theory)/(cl_kk_theory), yerr=sigma_cl_kk/cl_kk_theory, color=\"black\", markersize=20)\n",
    "axs[1].axhline(0)\n",
    "axs[1].set_xlabel(r\"$\\ell$\")\n",
    "axs[1].set_ylabel(\"Fractional error\")\n",
    "plt.savefig(\"comparison_lmax_7500.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução:\n",
    "def chi2(Omega_m, sigma_8):\n",
    "    ell_theory, cl_kk_theory = get_cl_kk(Omega_m, sigma_8, lmax=7500)\n",
    "    fac_theory = (ell_theory**4 + 2*ell_theory**3 - ell_theory*2 - 2*ell_theory)/4\n",
    "    cl_theory_interpolator = interp1d(ell_theory, fac_theory*cl_kk_theory)\n",
    "    cl_kk_theory = cl_theory_interpolator(ell_data)\n",
    "    delta = cl_kk_theory - cl_kk_data\n",
    "    return np.sum((delta/sigma_cl_kk)**2)\n",
    "\n",
    "chi2(0.35, 0.840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0acb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a covariance\n",
    "cov = np.loadtxt(\"cov_clgg.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d159f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "from time import time\n",
    "class MCMCWalker:\n",
    "    \"\"\"\n",
    "        Helper class for managing MCMCs. The class contains methods for performing Monte Carlo steps and saves the state.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Hard-coding an initial point based on the exploration\n",
    "        initial_om = 0.2\n",
    "        initial_sigma8 = 0.880\n",
    "        initial_params = [initial_om, initial_sigma8]\n",
    "        initial_chi2 = chi2(*initial_params)\n",
    "        initial_sample = {\n",
    "            'params': initial_params,\n",
    "            'chi2': initial_chi2,\n",
    "            'weight': 1,\n",
    "        }\n",
    "        self.samples = [initial_sample]\n",
    "\n",
    "    def accept_sample(self, params, chi2):\n",
    "        sample = {\n",
    "            'params': params,\n",
    "            'chi2': chi2,\n",
    "            'weight': 1\n",
    "        }\n",
    "        self.samples.append(sample)\n",
    "\n",
    "    def step(self):\n",
    "        while True:\n",
    "            current_chi2 = self.samples[-1]['chi2']\n",
    "            step = np.random.multivariate_normal(np.zeros(2), cov)\n",
    "            new_om = self.samples[-1]['params'][0] + step[0]\n",
    "            new_s8 = self.samples[-1]['params'][1] + step[1]\n",
    "            \n",
    "            new_params = [new_om, new_s8]\n",
    "            if new_om < 0 or new_om > 1 or new_s8 > 1.5 or new_s8 < 0.4:\n",
    "                # Reject point outside the prior\n",
    "                self.samples[-1]['weight'] += 1\n",
    "                continue\n",
    "            new_chi2 = chi2(*new_params)\n",
    "            if new_chi2 == np.nan:\n",
    "                # Reject points that have problematic chi2\n",
    "                self.samples[-1]['weight'] += 1\n",
    "                continue\n",
    "            if new_chi2 < current_chi2:\n",
    "                self.accept_sample(new_params, new_chi2)\n",
    "                break\n",
    "            else:\n",
    "                r = uniform(0, 1)\n",
    "                if r < np.exp(-(new_chi2 - current_chi2)/2):\n",
    "                    self.accept_sample(new_params, new_chi2)\n",
    "                    break\n",
    "                else:\n",
    "                    self.samples[-1]['weight'] += 1 # Increment weight\n",
    "                    continue\n",
    "            \n",
    "    \n",
    "    def gelman_rubin(self, n_split):\n",
    "        all_params = np.array(\n",
    "            [sample['params'] for sample in self.samples]\n",
    "        )[:-(len(self.samples)%n_split)]\n",
    "        np.random.shuffle(all_params)\n",
    "        split_params = np.split(all_params, n_split)\n",
    "        avg = np.mean(split_params, axis=1)\n",
    "        std = np.std(split_params, axis=1)\n",
    "        avg_of_std = np.mean(std, axis=0)\n",
    "        std_of_avg = np.std(avg, axis=0)\n",
    "        R_minus_one = std_of_avg/avg_of_std\n",
    "        return np.max(R_minus_one)\n",
    "\n",
    "def run_mcmc(w):\n",
    "    print(\"Starting MCMC\")\n",
    "    start = time()\n",
    "    while True:\n",
    "        for _ in range(10): w.step()\n",
    "        R_minus_one = w.gelman_rubin(4)\n",
    "        print(f\"At {len(w.samples)} samples, R-1 = {R_minus_one}\")\n",
    "        if R_minus_one < 0.025: break \n",
    "    print(f\"MCMC Converged! Took {time() - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a58f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = MCMCWalker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce849d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mcmc(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getdist\n",
    "from getdist import plots\n",
    "\n",
    "def getdist_chain(w):\n",
    "    \"\"\"\n",
    "        Função auxiliar que transforma as amostras cruas em um objeto `getdist.MCSamples`\n",
    "        A função também define o parâmetro derivado `S8`\n",
    "    \"\"\"\n",
    "    mcmc = getdist.MCSamples(\n",
    "        samples=np.array([sample['params'] + [sample['chi2']] for sample in w.samples]),\n",
    "        weights=np.array([sample['weight'] for sample in w.samples]),\n",
    "        names=[\"Omega_m\", \"sigma_8\", \"chi2\"],\n",
    "        labels=[\"\\\\Omega_m\", \"\\\\sigma_8\", \"\\\\chi^2\"],\n",
    "        ranges={\"Omega_m\": (0, None)}\n",
    "    )\n",
    "    mcmc.removeBurn(0.3)\n",
    "    mcmc.addDerived(mcmc[\"sigma_8\"]*np.sqrt(mcmc[\"Omega_m\"]/0.3), name=\"S8\", label=\"S_8\")\n",
    "    return mcmc\n",
    "\n",
    "chain = getdist_chain(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter intervalos de confiança 1D\n",
    "params = [\"Omega_m\", \"sigma_8\", \"S8\"]\n",
    "print(\"1D confidence intervals (68%):\")\n",
    "for param in params:\n",
    "  print(chain.getInlineLatex(param, limit=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo contornos de confiança 2D, o corner plot\n",
    "p = getdist.plots.get_subplot_plotter()\n",
    "p.settings.axes_fontsize=22\n",
    "p.settings.axes_labelsize=22\n",
    "p.triangle_plot(\n",
    "    chain,\n",
    "    params=params,\n",
    "    filled=True,\n",
    "    contour_colors=[\"#406421\"]\n",
    ")\n",
    "p.export(\"mcmc_shear.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977976d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
